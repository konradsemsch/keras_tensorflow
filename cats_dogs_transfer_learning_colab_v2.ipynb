{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "keras_tensorflow",
      "language": "python",
      "name": "keras_tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "cats_dogs_transfer_learning_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUwI1vJqv7q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install all dependencies\n",
        "!pip install pandas numpy tensorflow==2.1.0rc0 sklearn jupyterlab matplotlib pillow packaging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkKmkPbetUPb",
        "colab_type": "code",
        "outputId": "71d45251-1e3c-48c3-d14f-872a40a27d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRhiDdhy2Aws",
        "colab_type": "code",
        "outputId": "0efd9dec-ccdf-49f6-9742-f3a153d4090f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQCZGq4rwm2d",
        "colab_type": "code",
        "outputId": "ec839267-95f4-461c-8d04-3414f07fe5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWAD02k4yiti",
        "colab_type": "code",
        "outputId": "af732a0f-90ba-4011-ffee-0abba7256fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls drive/My\\ Drive/Colab\\ Notebooks/data_tmp/dogs-vs-cats-small"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVgt6jpYqPB_",
        "colab_type": "code",
        "outputId": "a4f55acc-ae83-4e28-f923-c41fd9f547dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls drive/My\\ Drive/Colab\\ Notebooks/data_tmp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs-vs-cats-small  model_cats_transfer_learning_v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct7s_avYxNbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_dir = \"drive/My Drive/Colab Notebooks/data_tmp/dogs-vs-cats-small\"\n",
        "path_model = \"drive/My Drive/Colab Notebooks/data_tmp\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Tb3zQ0tUPj",
        "colab_type": "text"
      },
      "source": [
        "## Importing a trained Vgg16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaeWjNBatUPl",
        "colab_type": "text"
      },
      "source": [
        "A Vgg16 model that had the final dense layer trained already. Middle layers will now be fine-tuned (but only the top block)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPaLBJTwtUPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_base = tf.keras.models.load_model(path_model + '/model_cats_transfer_learning_v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwf5YIAltUPs",
        "colab_type": "code",
        "outputId": "362847ee-ae5f-4c42-b9e1-7e68c3ca47d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model_base.build(((None, 150, 150, 3))) # we need to initialize the model first with build()\n",
        "model_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  2097408   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 16,812,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2QwRRt_sxb5",
        "colab_type": "code",
        "outputId": "b8bab9f3-2928-407a-e765-d368c6f14aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# These are all high level layers of the model\n",
        "model_base.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.saving.saved_model.load.Model at 0x7fe816402588>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Flatten at 0x7fe816402908>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Dense at 0x7fe816402d30>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Dense at 0x7fe81640a198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9MpQT-nsAvb",
        "colab_type": "code",
        "outputId": "1da2a868-1394-4016-a0fe-6b3efd11cdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# In the first instacne we will unfreeze the top layers which we trained already\n",
        "print(\"Number of layers in the base model: \", len(model_base.layers))\n",
        "\n",
        "# Fine tune from this layer onwards (the first layer we will treat separately)\n",
        "freeze_from = 1\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in model_base.layers[freeze_from:]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgrQU50cth09",
        "colab_type": "code",
        "outputId": "bf777a52-596c-40b9-9131-f6f63b0a1274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Sanity check\n",
        "for layer in model_base.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.saving.saved_model.load.Model object at 0x7fe816402588> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Flatten object at 0x7fe816402908> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Dense object at 0x7fe816402d30> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Dense object at 0x7fe81640a198> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ5eXrapuWpO",
        "colab_type": "code",
        "outputId": "7c5df342-e8f8-4db5-e7ff-e57743bfc2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# Let's now take a separate look at the 1st layer which is the Vgg model\n",
        "model_base.layers[0].layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.saving.saved_model.load.InputLayer at 0x7fe81640a630>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81640aa90>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81640af98>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.MaxPooling2D at 0x7fe8164132e8>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe816413748>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe816413ba8>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.MaxPooling2D at 0x7fe816413eb8>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81641a358>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81641a7b8>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81641ac18>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.MaxPooling2D at 0x7fe81641af28>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe8164253c8>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe816425828>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe816425c88>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.MaxPooling2D at 0x7fe816425f98>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81642c438>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81642c898>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.Conv2D at 0x7fe81642ccf8>,\n",
              " <tensorflow.python.keras.saving.saved_model.load.MaxPooling2D at 0x7fe816434048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwgVcXfotUP4",
        "colab_type": "code",
        "outputId": "28715075-3d5d-4bfe-e3fd-020f5a379536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "print(\"Number of layers in the base model: \", len(model_base.layers[0].layers))\n",
        "\n",
        "# Fine tune from this layer onwards (the first layer we will treat separately)\n",
        "freeze_until = 7\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in model_base.layers[0].layers[:freeze_until]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCCv5GO0u6jy",
        "colab_type": "code",
        "outputId": "d2c25d69-0b24-43de-97ed-2fbf5c7437bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# Sanity check\n",
        "for layer in model_base.layers[0].layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.saving.saved_model.load.InputLayer object at 0x7fe81640a630> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81640aa90> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81640af98> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.MaxPooling2D object at 0x7fe8164132e8> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe816413748> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe816413ba8> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.MaxPooling2D object at 0x7fe816413eb8> False\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81641a358> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81641a7b8> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81641ac18> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.MaxPooling2D object at 0x7fe81641af28> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe8164253c8> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe816425828> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe816425c88> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.MaxPooling2D object at 0x7fe816425f98> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81642c438> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81642c898> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.Conv2D object at 0x7fe81642ccf8> True\n",
            "<tensorflow.python.keras.saving.saved_model.load.MaxPooling2D object at 0x7fe816434048> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wmPwYPvtUQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_base.compile(\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-5),\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0JZrD-tUQK",
        "colab_type": "code",
        "outputId": "fe917f1a-dc6f-495f-bcfb-f4b17c0b6868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  2097408   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 14,454,528\n",
            "Non-trainable params: 2,357,825\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVdJJDUNtUQR",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCVtTxf3tUQT",
        "colab_type": "text"
      },
      "source": [
        "We're gonna use the data image generator to read data batches one by one from disck instead of loading them all into memory at once, with some data augmentation techniques to prevent ovefitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJqvFAc3tUQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1. / 255, \n",
        "    rotation_range = 40, # rotating the image randomly by a number of degrees to each of the side\n",
        "    width_shift_range = 0.2, # sliding the image as a fraction of its width or height\n",
        "    height_shift_range = 0.2, \n",
        "    shear_range = 0.2, # changing the angle of the image (shearing)\n",
        "    zoom_range = 0.2, # slightly zooming inside the image\n",
        "    horizontal_flip = True, # possible when there is no assumption of horizontal asymmetry\n",
        "    fill_mode = 'nearest' # the strategy of how newly created pixels will be filled e.g. after width/ height shift\n",
        ")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6ARDKsatUQc",
        "colab_type": "code",
        "outputId": "5bfaee47-7894-4606-d88c-7cb0835eb266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dir = path_dir + '/train'\n",
        "valid_dir = path_dir + '/valid'\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size = (150, 150),\n",
        "        batch_size = 20,\n",
        "        class_mode = 'binary'\n",
        ")\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "        valid_dir,\n",
        "        target_size = (150, 150),\n",
        "        batch_size = 20,\n",
        "        class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1999 images belonging to 2 classes.\n",
            "Found 998 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBloCEpRtUQf",
        "colab_type": "text"
      },
      "source": [
        "## Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyyfecjxtUQg",
        "colab_type": "code",
        "outputId": "079c2366-907f-4a23-cff5-ecdb40233ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_base.fit_generator(\n",
        "    train_generator, \n",
        "    steps_per_epoch = 100, # 2000 samples, 20 per batches = 100 steps per each epoch\n",
        "    epochs = 100,\n",
        "    validation_data = valid_generator,\n",
        "    validation_steps = 50 # 1000 samples, 20 per batch = 50 steps per each epoch\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 100 steps, validate for 50 steps\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.2854 - accuracy: 0.8794 - val_loss: 0.2540 - val_accuracy: 0.8868\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.2140 - accuracy: 0.9105 - val_loss: 0.2080 - val_accuracy: 0.9158\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.1977 - accuracy: 0.9190 - val_loss: 0.2042 - val_accuracy: 0.9118\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.1703 - accuracy: 0.9290 - val_loss: 0.1696 - val_accuracy: 0.9299\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.1345 - accuracy: 0.9470 - val_loss: 0.1748 - val_accuracy: 0.9208\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.1247 - accuracy: 0.9555 - val_loss: 0.1410 - val_accuracy: 0.9439\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.1258 - accuracy: 0.9545 - val_loss: 0.1740 - val_accuracy: 0.9289\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.1077 - accuracy: 0.9510 - val_loss: 0.2213 - val_accuracy: 0.9088\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0901 - accuracy: 0.9670 - val_loss: 0.1556 - val_accuracy: 0.9349\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0824 - accuracy: 0.9700 - val_loss: 0.1658 - val_accuracy: 0.9319\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0875 - accuracy: 0.9705 - val_loss: 0.1982 - val_accuracy: 0.9339\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0636 - accuracy: 0.9770 - val_loss: 0.1571 - val_accuracy: 0.9429\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0643 - accuracy: 0.9735 - val_loss: 0.1204 - val_accuracy: 0.9529\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0639 - accuracy: 0.9750 - val_loss: 0.1626 - val_accuracy: 0.9339\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0508 - accuracy: 0.9815 - val_loss: 0.1859 - val_accuracy: 0.9309\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0567 - accuracy: 0.9790 - val_loss: 0.1706 - val_accuracy: 0.9329\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.1556 - val_accuracy: 0.9439\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0442 - accuracy: 0.9845 - val_loss: 0.2652 - val_accuracy: 0.9289\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0603 - accuracy: 0.9780 - val_loss: 0.1292 - val_accuracy: 0.9499\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.2159 - val_accuracy: 0.9299\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.2558 - val_accuracy: 0.9309\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 0.1398 - val_accuracy: 0.9479\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.3330 - val_accuracy: 0.9188\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.1588 - val_accuracy: 0.9419\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.1518 - val_accuracy: 0.9479\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 0.1596 - val_accuracy: 0.9449\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.2226 - val_accuracy: 0.9279\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 0.1985 - val_accuracy: 0.9349\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0376 - accuracy: 0.9880 - val_loss: 0.1973 - val_accuracy: 0.9419\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.1378 - val_accuracy: 0.9589\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0327 - accuracy: 0.9885 - val_loss: 0.1352 - val_accuracy: 0.9559\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.2124 - val_accuracy: 0.9409\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.1994 - val_accuracy: 0.9519\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.1648 - val_accuracy: 0.9469\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.1498 - val_accuracy: 0.9529\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.1320 - val_accuracy: 0.9629\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.2634 - val_accuracy: 0.9218\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.1421 - val_accuracy: 0.9529\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.1972 - val_accuracy: 0.9489\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.1946 - val_accuracy: 0.9449\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 0.1873 - val_accuracy: 0.9409\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0226 - accuracy: 0.9910 - val_loss: 0.3506 - val_accuracy: 0.9158\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.1599 - val_accuracy: 0.9529\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0197 - accuracy: 0.9905 - val_loss: 0.1374 - val_accuracy: 0.9539\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.1417 - val_accuracy: 0.9529\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.2077 - val_accuracy: 0.9519\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.1826 - val_accuracy: 0.9529\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.1671 - val_accuracy: 0.9509\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.2370 - val_accuracy: 0.9439\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0187 - accuracy: 0.9930 - val_loss: 0.1650 - val_accuracy: 0.9499\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.1762 - val_accuracy: 0.9599\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.1688 - val_accuracy: 0.9559\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.1494 - val_accuracy: 0.9609\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.1727 - val_accuracy: 0.9589\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.2508 - val_accuracy: 0.9449\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.2001 - val_accuracy: 0.9449\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.2298 - val_accuracy: 0.9419\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.2389 - val_accuracy: 0.9359\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.2372 - val_accuracy: 0.9279\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.3269 - val_accuracy: 0.9329\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.1485 - val_accuracy: 0.9579\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.2501 - val_accuracy: 0.9429\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.2042 - val_accuracy: 0.9539\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.4093 - val_accuracy: 0.9188\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0137 - accuracy: 0.9935 - val_loss: 0.1819 - val_accuracy: 0.9549\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0129 - accuracy: 0.9950 - val_loss: 0.1915 - val_accuracy: 0.9479\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1798 - val_accuracy: 0.9579\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0109 - accuracy: 0.9945 - val_loss: 0.2915 - val_accuracy: 0.9319\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.1700 - val_accuracy: 0.9549\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.1955 - val_accuracy: 0.9569\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.3094 - val_accuracy: 0.9359\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.1716 - val_accuracy: 0.9569\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.2454 - val_accuracy: 0.9419\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.2258 - val_accuracy: 0.9499\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.1529 - val_accuracy: 0.9559\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.2142 - val_accuracy: 0.9439\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.1771 - val_accuracy: 0.9569\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0075 - accuracy: 0.9965 - val_loss: 0.3266 - val_accuracy: 0.9409\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.1701 - val_accuracy: 0.9539\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.2180 - val_accuracy: 0.9389\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.2229 - val_accuracy: 0.9549\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.2041 - val_accuracy: 0.9469\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.3640 - val_accuracy: 0.9269\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0119 - accuracy: 0.9955 - val_loss: 0.2805 - val_accuracy: 0.9429\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 26s 255ms/step - loss: 0.0162 - accuracy: 0.9935 - val_loss: 0.2923 - val_accuracy: 0.9499\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.1997 - val_accuracy: 0.9399\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 26s 258ms/step - loss: 0.0128 - accuracy: 0.9940 - val_loss: 0.2496 - val_accuracy: 0.9439\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.2445 - val_accuracy: 0.9509\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.1847 - val_accuracy: 0.9559\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.4720 - val_accuracy: 0.9208\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 26s 255ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.2232 - val_accuracy: 0.9459\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 26s 257ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.1673 - val_accuracy: 0.9579\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1933 - val_accuracy: 0.9539\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.0192 - accuracy: 0.9910 - val_loss: 0.1403 - val_accuracy: 0.9609\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 25s 253ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.2169 - val_accuracy: 0.9469\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1737 - val_accuracy: 0.9629\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.0131 - accuracy: 0.9935 - val_loss: 0.2015 - val_accuracy: 0.9469\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 25s 255ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.1504 - val_accuracy: 0.9599\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.0116 - accuracy: 0.9945 - val_loss: 0.1535 - val_accuracy: 0.9529\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 0.1919 - val_accuracy: 0.9469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe81608bb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxramSGWtUQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the trained model\n",
        "model_base.save('drive/My Drive/Colab Notebooks/data_tmp/model_cats_transfer_learning_v2', save_format = 'tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afwqLHO4tUQp",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLCMQLbLtUQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model_base.evaluate(test_images, test_labels, verbose = 2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2FVlJ9atUQv",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kfPTlFftUQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model_base.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQh36ERtUQ2",
        "colab_type": "code",
        "outputId": "12b84f64-b827-4b08-bf6a-c65bea6dbb82",
        "colab": {}
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.4292335e-22, 1.6219846e-22, 3.8224264e-22, 2.2197426e-20,\n",
              "       1.6082298e-26, 4.0185693e-12, 2.1265178e-23, 2.1613789e-11,\n",
              "       4.5142590e-21, 1.0000000e+00], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO3cXKGHtUQ6",
        "colab_type": "code",
        "outputId": "828dc70a-f3ac-403f-f5ef-d32fb8065e78",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}